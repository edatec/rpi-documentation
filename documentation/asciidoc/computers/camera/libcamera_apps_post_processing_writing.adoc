[[writing-your-own-post-processing-stages]]
=== 编写自己的后处理阶段

libcamera-apps后处理框架不仅非常灵活，而且旨在使用户能够轻松创建自己的自定义后处理阶段。很容易包含OpenCV和TensorFlow Lite中已经可用的算法和例程。

我们热衷于接受和分发用户贡献的有趣的后处理阶段。

[[basic-post-processing-stages]]
==== 基本后处理阶段

后处理阶段有一个简单的API，用户可以通过从PostProcessingStage类派生来创建自己的API。下面列出了必须实现的成员函数，但请注意，对于简单阶段，某些函数可能是不必要的。

[cols=",^"]
|===
| `char const *Name() const` | 返回阶段的名称。这用于与 JSON 后处理配置文件中列出的阶段进行匹配。
| `void Read(boost::property_tree::ptree const &params)` | 此方法将从 JSON 文件中读取阶段的任何配置参数。
| `void AdjustConfig(std::string const &use_case, StreamConfiguration *config)` |此方法使阶段有机会影响摄像机的配置，尽管通常不需要实现它。
| `void Configure()` | 这在配置摄像机后立即调用。这是检查阶段是否有权访问所需的流的好时机，并且还可以分配可能需要的任何资源。
| `void Start()` | 相机启动时调用。此方法通常不是必需的。
| `bool Process(CompletedRequest &completed_request)` | 此方法呈现已完成的相机请求以进行后期处理，并且需要进行必要的像素处理或图像分析。如果后处理框架不将此请求传递到应用程序，则该函数返回true。
| `void Stop()` | 在相机停止时调用。通常，阶段需要关闭可能正在运行的任何处理（例如，如果它启动了任何异步线程）。.
| `void Teardown()` | 拆除摄像机配置时调用。这通常用于取消分配在Configure方法中设置的任何资源。
|===

编写自己的阶段的一些有用提示：

* 通常，该Process方法不应花费太长时间，因为它会阻塞成像管道并可能导致卡顿。当需要运行耗时的算法时，将它们委托给另一个异步线程可能会有所帮助。

* 将工作委派给另一个线程时，当前处理图像缓冲区的方式意味着需要复制它们。对于某些应用（如图像分析），使用“低分辨率”图像流而不是全分辨率图像可能是可行的。

* 后处理框架基于每帧添加多线程并行性。如果要在每一帧上运行，这有助于提高吞吐量。某些函数可能会在每个帧内提供并行性（例如 OpenCV 和 TFLite）。在这些情况下，最好序列化调用以抑制每帧并行性。

* 大多数流，尤其是低分辨率流，都具有 YUV420 格式。这些格式有时不适合OpenCV或TFLite，因此有时可能需要一个转换步骤。

* 当需要更改图像时，就地更改是最简单的策略。

* 任何阶段的实现都应始终包含RegisterStage调用。这将向系统注册您的新stage，以便在JSON文件中列出时可以正确地识别它。当然，您还需要将它添加到后处理文件夹的CMakeLists.txt中。

最简单的示例是 negate_stage.cpp，它“否定”图像（将黑白，反之亦然）。除了少量派生类样板文件外，它只包含六行代码。

接下来的复杂性是sobel_cv_stage.cpp 。这只使用几行OpenCV函数实现了Sobel过滤器。

[[tflite-stages]]
==== TFLite 阶段

对于想要使用TensorFlowLite分析图像的阶段，我们提供TfStage基类。这提供了一定数量的样板代码，并且通过从此类派生来实现基于 TFLite 的新阶段变得更加容易。特别是，它将模型的执行委托给另一个线程，以便仍然保持完整的相机帧速率 - 它只是模型将以较低的帧速率运行。

TfStage类实现所有通常必须重新定义的公共PostProcessingStage方法，但Name方法除外，它仍然必须提供。然后它给出了下面的虚方法，派生类应该实现这些虚方法。

[cols=",^"]
|===
| `void readExtras()` | The base class reads the named model and certain other parameters like the `refresh_rate`. This method can be supplied to read any extra parameters for the derived stage. It is also a good place to check that the loaded model looks as expected (i.e. has right input and output dimensions).
| `void checkConfiguration()` | The base class fetches the low resolution stream which TFLite will operate on, and the full resolution stream in case the derived stage needs it. This method is provided for the derived class to check that the streams it requires are present. In case any required stream is missing, it may elect simply to avoid processing any images, or it may signal a fatal error.
| `void interpretOutputs()` | The TFLite model runs asynchronously so that it can run "every few frames" without holding up the overall framerate. This method gives the derived stage the chance to read and interpret the model's outputs, running right after the model itself and in that same thread.
| `void applyResults()` | Here we are running once again in the main thread and so this method should run reasonably quickly so as not to hold up the supply of frames to the application. It is provided so that the last results of the model (which might be a few frames ago) can be applied to the current frame. Typically this would involve attaching metadata to the image, or perhaps drawing something onto the main image.
|===

For further information, readers are referred to the supplied example code implementing the `ObjectClassifyTfStage` and `PoseEstimationTfStage` classes.
