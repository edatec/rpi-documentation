[[libcamera-detect]]
=== `libcamera-detect`


libcamera-detect在任何Raspberry Pi OS发行版中都没有默认提供，但可以由xref:camera_software.adoc#post-processing-with-tensorflow-lite[安装了TensorFlow Lite]安装了TensorFlow Lite的用户构建。在这种情况下，请参考xref:camera_software.adoc#building-libcamera-and-libcamera-apps[libcamera-apps构建说明]。您需要使用-DENABLE_TFLITE=1运行cmake。

此应用程序运行预览窗口并使用Google MobileNet v1 SSD（单次检测器）神经网络监控内容，该神经网络经过训练，可以使用Coco数据集识别大约80类对象。它应该识别人，汽车，猫和许多其他物体。
它首先运行预览窗口，每当检测到目标对象时，它都会执行全分辨率 JPEG 捕获，然后返回预览模式继续监视。它提供了几个不适用于其他地方的其他命令行选项：

`--object <name>`

使用给定的<name> .该名称应取自模型的标签文件。

`--gap <number>`

在捕获后至少等待这么多帧，然后再执行另一帧。这是必要的，因为神经网络不会在每一帧上运行，因此在考虑再次捕获之前，最好给它几帧以再次运行。

请参阅  xref:camera_software.adoc#object_detect_tf-stage[TensorFlow Lite 对象检测器] 部分，了解有关如何获取和使用此模型的更多一般信息。但举个例子，你可能会在外出时秘密监视你的猫：

[,bash]
----
libcamera-detect -t 0 -o cat%04d.jpg --lores-width 400 --lores-height 300 --post-process-file object_detect_tf.json --object cat
----
